# Here the most important graph:
[*Same Task, More Tokens: the Impact of Input Length on the Reasoning Performance of Large Language Models*](https://huggingface.co/papers/2402.14848) (2024-02-19; Mosh Levy, Alon Jacoby, Yoav Goldberg) suggests that reasoning capacity drops off pretty sharply from 250 to 1000 tokens, starting to flatten out between 2000-3000 tokens.

![](/posts/images/mostimportantgraph.png)

## Milestones of software development
- Assembly -> C, C -> Java, C -> Python like milestones. Easier to access/manage to business logic. Overall less context to deal with, straight to business. Nowadays, the programming language and business logic is already paired well. %99 the time, no one plays outside of the business logic. Most decisions are made for fast PoC with most already available sw support. People needs to learn compiler configurations, tricks, algorithms, standart libraries. 
- Manual Testing -> Testing Frameworks/Teams. Just release it process -> QA process. DevOPS/Container solutions.  Making things costs less, constantly checking the latest status.
- OpenSource/FreeSource

For the next iteration phase of software development, we need to figure put a effective way to feed AI systems with observability data[logs, metrics, traces]. 

So what we see here ?
- Company IPs are sometimes creates more accurate results, but benchmarks are changing everyday. So best business ideas are usually are not creating best models.